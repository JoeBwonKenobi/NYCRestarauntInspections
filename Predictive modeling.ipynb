{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82afade9",
   "metadata": {},
   "source": [
    "# **Predictive Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c3d4c",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5883f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy\n",
    "import numpy as np\n",
    "\n",
    "#Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import re\n",
    "\n",
    "\n",
    "#sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "set_config(display = 'diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d679a4",
   "metadata": {},
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33aea1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading NYC Restaraunt Data\n",
    "rdf = pd.read_csv('rdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c99dceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209141 entries, 0 to 209140\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   CAMIS                  209141 non-null  int64  \n",
      " 1   DBA                    208544 non-null  object \n",
      " 2   BORO                   209141 non-null  object \n",
      " 3   BUILDING               208824 non-null  object \n",
      " 4   STREET                 209135 non-null  object \n",
      " 5   ZIPCODE                206455 non-null  float64\n",
      " 6   CUISINE DESCRIPTION    206702 non-null  object \n",
      " 7   INSPECTION DATE        209141 non-null  object \n",
      " 8   ACTION                 206702 non-null  object \n",
      " 9   VIOLATION CODE         205553 non-null  object \n",
      " 10  VIOLATION DESCRIPTION  205553 non-null  object \n",
      " 11  CRITICAL FLAG          209141 non-null  object \n",
      " 12  SCORE                  199209 non-null  float64\n",
      " 13  GRADE                  102462 non-null  object \n",
      " 14  GRADE DATE             93826 non-null   object \n",
      " 15  INSPECTION TYPE        206702 non-null  object \n",
      " 16  Latitude               208881 non-null  float64\n",
      " 17  Longitude              208881 non-null  float64\n",
      " 18  Council District       205918 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(13)\n",
      "memory usage: 30.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Glance of inspection data\n",
    "rdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46913a80",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b2fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns that do not affect predicting the classification question of will a restaurant pass an inspection\n",
    "rdf.drop(['Latitude', 'Longitude', 'Council District', 'ZIPCODE', 'BUILDING', 'STREET', 'VIOLATION DESCRIPTION', 'VIOLATION CODE', 'CRITICAL FLAG', 'ACTION', 'GRADE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66990824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209141 entries, 0 to 209140\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   CAMIS                209141 non-null  int64  \n",
      " 1   DBA                  208544 non-null  object \n",
      " 2   BORO                 209141 non-null  object \n",
      " 3   CUISINE DESCRIPTION  206702 non-null  object \n",
      " 4   INSPECTION DATE      209141 non-null  object \n",
      " 5   SCORE                199209 non-null  float64\n",
      " 6   GRADE DATE           93826 non-null   object \n",
      " 7   INSPECTION TYPE      206702 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 12.8+ MB\n"
     ]
    }
   ],
   "source": [
    "rdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6002946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'GRADE DATE' and ' 'INSPECTION DATE' columns to datetime type\n",
    "#rdf['INSPECTION DATE'] = pd.to_datetime(rdf['INSPECTION DATE'])\n",
    "#rdf['GRADE DATE'] = pd.to_datetime(rdf['GRADE DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8cb4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to eliminate restaurants that have not yet recieved their inspection\n",
    "def filter_inspected_restaurants(rdf):\n",
    "    # Filter out rows with '1/1/1900' date\n",
    "    filtered_dataframe = rdf[rdf['INSPECTION DATE'] != '1900-01-01']\n",
    "\n",
    "    return filtered_dataframe\n",
    "# Applying the filter function to the column Inpection date\n",
    "rdf = filter_inspected_restaurants(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e46e6653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 139254 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicate rows in the dataset\n",
    "print(f'There are {rdf.duplicated().sum()} duplicate rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "231f6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicated Rows\n",
    "rdf = rdf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201b5438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "# Comfirming there are no more duplicates \n",
    "print(f'There are {rdf.duplicated().sum()} duplicate rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8424f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31379, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "rdf[rdf.isna().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed01584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAMIS                      0\n",
       "DBA                      597\n",
       "BORO                       0\n",
       "CUISINE DESCRIPTION     2439\n",
       "INSPECTION DATE            0\n",
       "SCORE                   8546\n",
       "GRADE DATE             31376\n",
       "INSPECTION TYPE         2439\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying the columns containing missing values\n",
    "rdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "000629a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRADE DATE</th>\n",
       "      <td>31376</td>\n",
       "      <td>44.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCORE</th>\n",
       "      <td>8546</td>\n",
       "      <td>12.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUISINE DESCRIPTION</th>\n",
       "      <td>2439</td>\n",
       "      <td>3.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSPECTION TYPE</th>\n",
       "      <td>2439</td>\n",
       "      <td>3.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBA</th>\n",
       "      <td>597</td>\n",
       "      <td>0.85%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Total Percent\n",
       "GRADE DATE           31376   44.9%\n",
       "SCORE                 8546  12.23%\n",
       "CUISINE DESCRIPTION   2439   3.49%\n",
       "INSPECTION TYPE       2439   3.49%\n",
       "DBA                    597   0.85%"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing data in data \n",
    "def check_missing_data(rdf):\n",
    "    total = rdf.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (rdf.isnull().sum()/rdf.isnull().count()*100).sort_values(ascending = False)\n",
    "    percent = percent.round(2).astype(str) + '%'\n",
    "    missing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data\n",
    "missing_data_result = check_missing_data(rdf)\n",
    "missing_data_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6723631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean restaurant names\n",
    "def clean_restaurant_name(name):\n",
    "    # Check if the input is a string\n",
    "    if isinstance(name, str):\n",
    "        # Remove store numbers using regular expression\n",
    "        cleaned_name = re.sub(r'#\\d+', '', name)\n",
    "        \n",
    "        # Remove all numeric characters\n",
    "        cleaned_name = re.sub(r'\\d+', '', cleaned_name)\n",
    "    \n",
    "        # Remove leading and trailing whitespace\n",
    "        cleaned_name = cleaned_name.strip()\n",
    "    \n",
    "        return cleaned_name\n",
    "    else:\n",
    "        return name  # Return the input unchanged for non-string values\n",
    "\n",
    "# Apply the clean_restaurant_name function to the 'DBA' column\n",
    "rdf['Cleaned Restaurant Name'] = rdf['DBA'].apply(clean_restaurant_name)\n",
    "\n",
    "# Drop the original 'DBA' column if you want\n",
    "rdf.drop(columns=['DBA'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f437ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_missing_grade_date_rows(rdf):\n",
    "    \"\"\"\n",
    "    Eliminate rows with missing data in the \"GRADE DATE\" column.\n",
    "\n",
    "    Returns:\n",
    "    - Cleaned DataFrame without rows with missing \"GRADE DATE\"\n",
    "    \"\"\"\n",
    "    # Drop rows with missing values in the \"GRADE DATE\" column\n",
    "    cleaned_dataframe = rdf.dropna(subset=[\"GRADE DATE\"])\n",
    "\n",
    "    return cleaned_dataframe\n",
    "\n",
    "rdf = eliminate_missing_grade_date_rows(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05f0cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out only the initial inspections and re-inspections\n",
    "def filter_inspection_type(rdf):\n",
    "    \"\"\"\n",
    "    Filter rows based on the values in the \"INSPECTION TYPE\" column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing only rows with specified inspection types\n",
    "    \"\"\"\n",
    "    inspection_types_to_keep = ['Cycle Inspection / Initial Inspection', 'Cycle Inspection / Re-inspection']\n",
    "    filtered_rdf = rdf.loc[rdf['INSPECTION TYPE'].isin(inspection_types_to_keep)]\n",
    "\n",
    "    return filtered_rdf\n",
    "\n",
    "rdf = filter_inspection_type(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e766408",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50001249    5\n",
      "40879245    5\n",
      "50044250    5\n",
      "50035292    5\n",
      "40717234    5\n",
      "           ..\n",
      "50032876    1\n",
      "50079992    1\n",
      "50110649    1\n",
      "50085970    1\n",
      "50070120    1\n",
      "Name: CAMIS, Length: 18859, dtype: int64\n",
      "Manhattan        11620\n",
      "Brooklyn          8002\n",
      "Queens            7201\n",
      "Bronx             2705\n",
      "Staten Island     1163\n",
      "Name: BORO, dtype: int64\n",
      "American                    6631\n",
      "Coffee/Tea                  2515\n",
      "Chinese                     2289\n",
      "Pizza                       1855\n",
      "Bakery Products/Desserts    1184\n",
      "                            ... \n",
      "Californian                    2\n",
      "Basque                         2\n",
      "Chilean                        2\n",
      "Iranian                        1\n",
      "Lebanese                       1\n",
      "Name: CUISINE DESCRIPTION, Length: 87, dtype: int64\n",
      "03/03/2022    105\n",
      "02/28/2023    104\n",
      "12/01/2022    103\n",
      "02/27/2023    103\n",
      "01/24/2022    103\n",
      "             ... \n",
      "05/27/2023      1\n",
      "06/29/2016      1\n",
      "05/28/2016      1\n",
      "09/20/2021      1\n",
      "02/27/2018      1\n",
      "Name: INSPECTION DATE, Length: 1387, dtype: int64\n",
      "12.0     5276\n",
      "13.0     4170\n",
      "10.0     3355\n",
      "9.0      2482\n",
      "7.0      2391\n",
      "         ... \n",
      "66.0        1\n",
      "85.0        1\n",
      "74.0        1\n",
      "76.0        1\n",
      "102.0       1\n",
      "Name: SCORE, Length: 87, dtype: int64\n",
      "03/03/2022    105\n",
      "02/28/2023    104\n",
      "12/01/2022    103\n",
      "02/27/2023    103\n",
      "01/24/2022    103\n",
      "             ... \n",
      "05/27/2023      1\n",
      "06/29/2016      1\n",
      "05/28/2016      1\n",
      "09/20/2021      1\n",
      "02/27/2018      1\n",
      "Name: GRADE DATE, Length: 1387, dtype: int64\n",
      "Cycle Inspection / Initial Inspection    19078\n",
      "Cycle Inspection / Re-inspection         11613\n",
      "Name: INSPECTION TYPE, dtype: int64\n",
      "DUNKIN             817\n",
      "STARBUCKS          492\n",
      "SUBWAY             361\n",
      "MCDONALD'S         358\n",
      "POPEYES            189\n",
      "                  ... \n",
      "APPLE GARDEN         1\n",
      "THAI TERMINAL        1\n",
      "E BAR                1\n",
      "FUNNY BBQ BAR        1\n",
      "ZARA CAFE GRILL      1\n",
      "Name: Cleaned Restaurant Name, Length: 14783, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function for value counts of the columns \n",
    "for col in rdf.columns:\n",
    "    print(rdf[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06263fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting subset of only restaurants from Brooklyn\n",
    "rdf = rdf[rdf['BORO'].str.lower() == 'brooklyn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f94fd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting subset of only restaurants in Brooklyn that have pizza in the cuisine description\n",
    "rdf = rdf[(rdf['CUISINE DESCRIPTION'].str.lower() == 'pizza')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f280cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Handling missing values and date columns\n",
    "rdf['INSPECTION DATE'] = pd.to_datetime(rdf['INSPECTION DATE'], errors='coerce')\n",
    "rdf['year'] = rdf['INSPECTION DATE'].dt.year\n",
    "rdf['month'] = rdf['INSPECTION DATE'].dt.month\n",
    "rdf['day'] = rdf['INSPECTION DATE'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6532ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'BORO' and 'CUISINE DESCRIPTION' now that only the pizza restaurants in Brooklyn remain\n",
    "rdf.drop(['BORO', 'CUISINE DESCRIPTION', 'INSPECTION DATE', 'GRADE DATE', 'INSPECTION TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07dd9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdf = pd.get_dummies(rdf.drop(['date_column'], axis=1), columns=['Cleaned Restaurant Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5c92970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 528 entries, 143 to 208403\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   CAMIS                    528 non-null    int64  \n",
      " 1   SCORE                    528 non-null    float64\n",
      " 2   Cleaned Restaurant Name  528 non-null    object \n",
      " 3   year                     528 non-null    int64  \n",
      " 4   month                    528 non-null    int64  \n",
      " 5   day                      528 non-null    int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 28.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Looking at the remaining data after cleaning\n",
    "rdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133edfb3",
   "metadata": {},
   "source": [
    "# **Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21898dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the target variable\n",
    "X= rdf.drop('SCORE', axis=1)\n",
    "y= rdf['SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62059c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30669f0",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8af7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "# Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "# Imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# Instantiate the selectors\n",
    "num_selector = make_column_selector(dtype_include='number')\n",
    "cat_selector = make_column_selector(dtype_include='object')\n",
    "# Forming pipelines\n",
    "num_pipe = make_pipeline(imputer, scaler)\n",
    "cat_pipe = make_pipeline(ohe)\n",
    "# Column Transformer to apply different transformers to different subsets of columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipe, num_selector),\n",
    "        ('cat', cat_pipe, cat_selector)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Random Forest Classifier as a transformer\n",
    "rf_transformer = RandomForestClassifier()\n",
    "\n",
    "# Final pipeline combining preprocessing and modeling\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf_transformer', rf_transformer)\n",
    "])\n",
    "\n",
    "# Now you can use the pipeline for fitting and predicting\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d9cf5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tuples\n",
    "num_tuple = (num_pipe, num_selector)\n",
    "cat_tuple = (cat_pipe, cat_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c925bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate preprocessor Transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, make_column_selector(dtype_include='number')),\n",
    "        ('cat', ohe, make_column_selector(dtype_include='object'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e97ae024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;)])),\n",
       "                (&#x27;rf_transformer&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;)])),\n",
       "                (&#x27;rf_transformer&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00>),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50>)])),\n",
       "                ('rf_transformer', RandomForestClassifier())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the pipeline\n",
    "pipe = Pipeline([('preprocessor', preprocessor), ('rf_transformer', rf_transformer)])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7069065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;)])),\n",
       "                (&#x27;rf_transformer&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;)])),\n",
       "                (&#x27;rf_transformer&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADE8D00>),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001CD6ADDFE50>)])),\n",
       "                ('rf_transformer', RandomForestClassifier())])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit on the Train\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f15dcc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 12.,  4., 12.,  9., 11., 12., 13., 12., 10., 12., 12., 12.,\n",
       "       10., 12., 12., 13.,  7., 10., 13., 13., 12., 27., 12., 11.,  7.,\n",
       "       13.,  9., 12., 13., 13., 10.,  7., 11., 12., 10., 13., 12., 12.,\n",
       "       12.,  9., 13., 12., 12.,  9., 12.,  7., 13., 12., 13., 12., 12.,\n",
       "       12., 13., 12., 12., 13., 13., 10.,  3., 13., 12., 12., 12., 12.,\n",
       "       12., 12., 10., 12., 13., 12., 12.,  0., 12.,  3., 12., 12., 12.,\n",
       "        2., 12., 13.,  4.,  9., 17., 12.,  9.,  4., 10., 12., 12., 12.,\n",
       "       12., 12., 12.,  0., 12.,  7., 12., 13., 23., 13.,  3., 10., 13.,\n",
       "       13., 12.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "947261d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11320754716981132"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32fa671c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 540 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: \"DOMINO'S\"\n\n--------------------------------------------------------------------------------\n432 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: \"JOE'S PIZZA\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(rf_classifier, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Display the best hyperparameters\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 540 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n108 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: \"DOMINO'S\"\n\n--------------------------------------------------------------------------------\n432 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"C:\\Users\\davyd\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: \"JOE'S PIZZA\"\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Hyperparameter Tuning using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Step 4: Evaluate on Test Set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Display the accuracy and classification report\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 5: Feature Importance\n",
    "# Display feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': best_rf_model.feature_importances_})\n",
    "print(\"\\nFeature Importance:\\n\", feature_importance.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d669002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89707b7c",
   "metadata": {},
   "source": [
    "\n",
    "- Load your dataset, replace 'your_data.csv' with your data file. data = pd.read_csv('your_data.csv') \n",
    "- Assuming your dataset has various features and 'GRADE' as the target variable. \n",
    "- Replace these with your actual feature and target column names. \n",
    "- Preprocess the data X = data.drop(columns=['GRADE'])  \n",
    "- Features y = data['GRADE']  \n",
    "- Target variable  \n",
    "- Handle missing data (you may need more advanced methods) X.fillna(0, inplace=True)  \n",
    "- Encode categorical variables (if needed) categorical_columns = X.select_dtypes(include=['object']).columns for col in categorical_columns:     le = LabelEncoder()     X[col] = le.fit_transform(X[col])  \n",
    "- Split the data into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "- Feature scaling (normalize numerical features) scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) \n",
    "- Choose a classification model (Random Forest in this example) model = RandomForestClassifier(random_state=42) \n",
    "- Hyperparameter tuning using GridSearchCV (you may need more parameters) param_grid = {     'n_estimators': [100, 200],     'max_depth': [None, 10, 20],     'min_samples_split': [2, 5],     'min_samples_leaf': [1, 2] }  grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1) grid_search.fit(X_train, y_train)\n",
    "- Get the best model from hyperparameter tuning best_model = grid_search.best_estimator_ \n",
    "- Train the best model best_model.fit(X_train, y_train)  # Make predictions on the test set y_pred = best_model.predict(X_test) \n",
    "- Evaluate the model accuracy = accuracy_score(y_test, y_pred) print(f'Accuracy: {accuracy:.2f}')  \n",
    "- Print classification report for more detailed evaluation print(classification_report(y_test, y_pred)) \n",
    "- Use the trained model to make predictions on new data new_data = pd.DataFrame({     'Feature1': [value1],     'Feature2': [value2],   \n",
    "- Add more features as needed })  \n",
    "- Preprocess new data similarly to training data (handle missing values, encoding, scaling) new_data.fillna(0, inplace=True) new_data[categorical_columns] = le.transform(new_data[categorical_columns]) new_data = scaler.transform(new_data)  predicted_grade = best_model.predict(new_data) print(f'Predicted Grade: {predicted_grade[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b6bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e42e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ff083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
