{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82afade9",
   "metadata": {},
   "source": [
    "# **Predictive Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3343019",
   "metadata": {},
   "source": [
    "Joseph Lardie\n",
    "\n",
    "November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c3d4c",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5883f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy\n",
    "import numpy as np\n",
    "\n",
    "#Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import re\n",
    "\n",
    "#sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "set_config(display = 'diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d679a4",
   "metadata": {},
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33aea1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading NYC Restaraunt Inspections Data\n",
    "rdf = pd.read_csv('rdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c99dceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210611 entries, 0 to 210610\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   CAMIS                  210611 non-null  int64  \n",
      " 1   DBA                    209970 non-null  object \n",
      " 2   BORO                   210611 non-null  object \n",
      " 3   BUILDING               210308 non-null  object \n",
      " 4   STREET                 210607 non-null  object \n",
      " 5   ZIPCODE                207890 non-null  float64\n",
      " 6   CUISINE DESCRIPTION    208186 non-null  object \n",
      " 7   INSPECTION DATE        210611 non-null  object \n",
      " 8   ACTION                 208186 non-null  object \n",
      " 9   VIOLATION CODE         207055 non-null  object \n",
      " 10  VIOLATION DESCRIPTION  207055 non-null  object \n",
      " 11  CRITICAL FLAG          210611 non-null  object \n",
      " 12  SCORE                  200542 non-null  float64\n",
      " 13  GRADE                  103135 non-null  object \n",
      " 14  GRADE DATE             94324 non-null   object \n",
      " 15  INSPECTION TYPE        208186 non-null  object \n",
      " 16  Latitude               210332 non-null  float64\n",
      " 17  Longitude              210332 non-null  float64\n",
      " 18  Council District       207348 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(13)\n",
      "memory usage: 30.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Glance of Inspections Data\n",
    "rdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46913a80",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b2fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns that do not affect predicting the classification question of will a restaurant pass an inspection\n",
    "rdf.drop(['Latitude', 'Longitude', 'Council District', 'ZIPCODE', 'BUILDING', 'STREET', 'VIOLATION DESCRIPTION', 'VIOLATION CODE', 'CRITICAL FLAG', 'ACTION', 'GRADE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66990824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210611 entries, 0 to 210610\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   CAMIS                210611 non-null  int64  \n",
      " 1   DBA                  209970 non-null  object \n",
      " 2   BORO                 210611 non-null  object \n",
      " 3   CUISINE DESCRIPTION  208186 non-null  object \n",
      " 4   INSPECTION DATE      210611 non-null  object \n",
      " 5   SCORE                200542 non-null  float64\n",
      " 6   GRADE DATE           94324 non-null   object \n",
      " 7   INSPECTION TYPE      208186 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspection data after dropping irrelevant columns\n",
    "rdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8cb4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to eliminate restaurants that have not yet recieved their inspection\n",
    "def filter_inspected_restaurants(rdf):\n",
    "    # Filter out rows with '1/1/1900' date\n",
    "    filtered_dataframe = rdf[rdf['INSPECTION DATE'] != '1900-01-01']\n",
    "\n",
    "    return filtered_dataframe\n",
    "# Applying the filter function to the column Inpection date\n",
    "rdf = filter_inspected_restaurants(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46e6653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 140333 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicate rows in the dataset\n",
    "print(f'There are {rdf.duplicated().sum()} duplicate rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231f6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicated Rows\n",
    "rdf = rdf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201b5438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "# Comfirming there are no more duplicates \n",
    "print(f'There are {rdf.duplicated().sum()} duplicate rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8424f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31613, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "rdf[rdf.isna().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed01584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAMIS                      0\n",
       "DBA                      641\n",
       "BORO                       0\n",
       "CUISINE DESCRIPTION     2425\n",
       "INSPECTION DATE            0\n",
       "SCORE                   8636\n",
       "GRADE DATE             31610\n",
       "INSPECTION TYPE         2425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying the columns containing missing values\n",
    "rdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6723631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean restaurant names\n",
    "def clean_restaurant_name(name):\n",
    "    # Check if the input is a string\n",
    "    if isinstance(name, str):\n",
    "        # Remove store numbers using regular expression\n",
    "        cleaned_name = re.sub(r'#\\d+', '', name)\n",
    "        \n",
    "        # Remove all numeric characters\n",
    "        cleaned_name = re.sub(r'\\d+', '', cleaned_name)\n",
    "    \n",
    "        # Remove leading and trailing whitespace\n",
    "        cleaned_name = cleaned_name.strip()\n",
    "    \n",
    "        return cleaned_name\n",
    "    else:\n",
    "        return name  # Return the input unchanged for non-string values\n",
    "\n",
    "# Apply the clean_restaurant_name function to the 'DBA' column\n",
    "rdf['Cleaned Restaurant Name'] = rdf['DBA'].apply(clean_restaurant_name)\n",
    "\n",
    "# Drop the original 'DBA' column if you want\n",
    "rdf.drop(columns=['DBA'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f57be185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70278 entries, 0 to 210588\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   CAMIS                    70278 non-null  int64  \n",
      " 1   BORO                     70278 non-null  object \n",
      " 2   CUISINE DESCRIPTION      67853 non-null  object \n",
      " 3   INSPECTION DATE          70278 non-null  object \n",
      " 4   SCORE                    61642 non-null  float64\n",
      " 5   GRADE DATE               38668 non-null  object \n",
      " 6   INSPECTION TYPE          67853 non-null  object \n",
      " 7   Cleaned Restaurant Name  69637 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "rdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f0cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out only the initial inspections and re-inspections\n",
    "def filter_inspection_type(rdf):\n",
    "    \"\"\"\n",
    "    Filter rows based on the values in the \"INSPECTION TYPE\" column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing only rows with specified inspection types\n",
    "    \"\"\"\n",
    "    inspection_types_to_keep = ['Cycle Inspection / Initial Inspection', 'Cycle Inspection / Re-inspection']\n",
    "    filtered_rdf = rdf.loc[rdf['INSPECTION TYPE'].isin(inspection_types_to_keep)]\n",
    "\n",
    "    return filtered_rdf\n",
    "\n",
    "rdf = filter_inspection_type(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e766408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40398688    13\n",
      "50042800    11\n",
      "50044250    11\n",
      "40879245    10\n",
      "41087273     9\n",
      "            ..\n",
      "41718160     1\n",
      "50115103     1\n",
      "50105346     1\n",
      "41362553     1\n",
      "40799593     1\n",
      "Name: CAMIS, Length: 20406, dtype: int64\n",
      "Manhattan        17621\n",
      "Brooklyn         12461\n",
      "Queens           10897\n",
      "Bronx             4228\n",
      "Staten Island     1781\n",
      "Name: BORO, dtype: int64\n",
      "American                    9392\n",
      "Chinese                     3958\n",
      "Coffee/Tea                  3479\n",
      "Pizza                       2940\n",
      "Bakery Products/Desserts    1814\n",
      "                            ... \n",
      "Chilean                        4\n",
      "Fruits/Vegetables              4\n",
      "Basque                         3\n",
      "Iranian                        2\n",
      "Haute Cuisine                  2\n",
      "Name: CUISINE DESCRIPTION, Length: 87, dtype: int64\n",
      "03/16/2023    144\n",
      "04/13/2023    137\n",
      "02/16/2023    136\n",
      "02/15/2023    136\n",
      "06/06/2023    132\n",
      "             ... \n",
      "06/01/2017      1\n",
      "06/15/2018      1\n",
      "12/17/2016      1\n",
      "05/29/2016      1\n",
      "02/21/2017      1\n",
      "Name: INSPECTION DATE, Length: 1498, dtype: int64\n",
      "12.0     5535\n",
      "13.0     4326\n",
      "10.0     3480\n",
      "9.0      2757\n",
      "7.0      2528\n",
      "         ... \n",
      "97.0        1\n",
      "108.0       1\n",
      "116.0       1\n",
      "120.0       1\n",
      "145.0       1\n",
      "Name: SCORE, Length: 111, dtype: int64\n",
      "03/03/2022    105\n",
      "02/28/2023    104\n",
      "02/27/2023    103\n",
      "12/01/2022    103\n",
      "01/24/2022    103\n",
      "             ... \n",
      "08/18/2016      1\n",
      "11/27/2017      1\n",
      "01/26/2018      1\n",
      "06/23/2017      1\n",
      "02/21/2017      1\n",
      "Name: GRADE DATE, Length: 1391, dtype: int64\n",
      "Cycle Inspection / Initial Inspection    35132\n",
      "Cycle Inspection / Re-inspection         11856\n",
      "Name: INSPECTION TYPE, dtype: int64\n",
      "DUNKIN                1043\n",
      "STARBUCKS              572\n",
      "SUBWAY                 506\n",
      "MCDONALD'S             427\n",
      "POPEYES                232\n",
      "                      ... \n",
      "Ikon Caterers            1\n",
      "Bar at the Garden        1\n",
      "M BAR & GRILL            1\n",
      "PIZZERIA LA GRANDE       1\n",
      "MONTAUK CLUB             1\n",
      "Name: Cleaned Restaurant Name, Length: 16089, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function for value counts of the columns \n",
    "for col in rdf.columns:\n",
    "    print(rdf[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13767e06",
   "metadata": {},
   "source": [
    "## **Selecting Brooklyn Restaurants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06263fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting subset of only restaurants from Brooklyn\n",
    "rdf = rdf[rdf['BORO'].str.lower() == 'brooklyn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f280cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values and date columns\n",
    "rdf['INSPECTION DATE'] = pd.to_datetime(rdf['INSPECTION DATE'], errors='coerce')\n",
    "rdf['year'] = rdf['INSPECTION DATE'].dt.year\n",
    "rdf['month'] = rdf['INSPECTION DATE'].dt.month\n",
    "rdf['day'] = rdf['INSPECTION DATE'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6532ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'BORO' and 'CUISINE DESCRIPTION' now that only restaurants in Brooklyn remain\n",
    "rdf.drop(['BORO', 'CUISINE DESCRIPTION', 'INSPECTION DATE', 'GRADE DATE', 'INSPECTION TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5c92970",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12461 entries, 41 to 210374\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   CAMIS                    12461 non-null  int64  \n",
      " 1   SCORE                    12461 non-null  float64\n",
      " 2   Cleaned Restaurant Name  12461 non-null  object \n",
      " 3   year                     12461 non-null  int64  \n",
      " 4   month                    12461 non-null  int64  \n",
      " 5   day                      12461 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 681.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Looking at the remaining data after cleaning\n",
    "rdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133edfb3",
   "metadata": {},
   "source": [
    "# **Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21898dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the target variable\n",
    "X= rdf.drop('SCORE', axis=1)\n",
    "y= rdf['SCORE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30669f0",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d62059c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8af7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputers\n",
    "freq_imputer = SimpleImputer(strategy='most_frequent')\n",
    "mean_imputer = SimpleImputer(strategy= 'mean')\n",
    "\n",
    "# Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=True, drop='first', handle_unknown='ignore')\n",
    "\n",
    "# Instantiate the selectors\n",
    "num_selector = make_column_selector(dtype_include='number')\n",
    "cat_selector = make_column_selector(dtype_include='object')\n",
    "\n",
    "# Forming pipelines\n",
    "num_pipe = make_pipeline(mean_imputer, scaler)\n",
    "cat_pipe = make_pipeline(freq_imputer, ohe)\n",
    "\n",
    "#Create Tuples\n",
    "num_tuple = ('num', num_pipe, num_selector)\n",
    "cat_tuple = ('cat', cat_pipe, cat_selector)\n",
    "\n",
    "#Make tuples for preprocessing the categorical and numeric columns\n",
    "num_tuple = (num_pipe, num_selector)\n",
    "cat_tuple = (cat_pipe, cat_selector)  \n",
    "\n",
    "\n",
    "#Create Column Transformer\n",
    "preprocessor= make_column_transformer(num_tuple, cat_tuple, remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f7a9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Fit and transform the preprocessing on the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted preprocessor\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e3f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDBE0&gt;),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=True))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDF40&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer()),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDBE0&gt;),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=True))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDF40&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDBE0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDF40&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('pipeline-1',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer()),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDBE0>),\n",
       "                                ('pipeline-2',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse=True))]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000002228A1CDF40>)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at how the preprocessor is organized\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b16dcc04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LinearRegression model\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Train the model using the preprocessed training sets\n",
    "regressor.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "111cf00f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ESPINAL DELI & GROCERY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions for training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_predictions_train \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mpredict(X_test_preprocessed)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\linear_model\\_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    367\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ESPINAL DELI & GROCERY'"
     ]
    }
   ],
   "source": [
    "# Make predictions for training data\n",
    "y_predictions_train = regressor.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = regressor.predict(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947261d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf1690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in X_train:\", X_train.isnull().sum().sum())\n",
    "print(\"Missing values in y_train:\", y_train.isnull().sum().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"Data types in X_train:\\n\", X_train.dtypes)\n",
    "print(\"Data type in y_train:\", y_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning using Grid Search\n",
    "param_grid = {\n",
    "    'rf_transformer__n_estimators': [50, 100, 200],\n",
    "    'rf_transformer__max_depth': [2, 5, 15, 20],\n",
    "    'rf_transformer__min_samples_split': [2, 5, 10],\n",
    "    'rf_transformer__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "lr_transformer = LogisticRegression(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy', error_score='raise')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "best_lg_model = grid_search.best_estimator_\n",
    "y_pred = best_lg_model.predict(X_test)\n",
    "\n",
    "# Evaluate on Test Set\n",
    "# Extract feature importances from the RandomForestClassifier within the pipeline\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_lr_model.named_steps['rf_transformer'].feature_importances_\n",
    "})\n",
    "print(\"\\nFeature Importance:\\n\", feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "# Display the accuracy and classification report\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Display feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': best_lr_model.feature_importances_})\n",
    "print(\"\\nFeature Importance:\\n\", feature_importance.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d669002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89707b7c",
   "metadata": {},
   "source": [
    "- Hyperparameter tuning using GridSearchCV (you may need more parameters) param_grid = {     'n_estimators': [100, 200],     'max_depth': [None, 10, 20],     'min_samples_split': [2, 5],     'min_samples_leaf': [1, 2] }  grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1) grid_search.fit(X_train, y_train)\n",
    "- Get the best model from hyperparameter tuning best_model = grid_search.best_estimator_ \n",
    "- Train the best model best_model.fit(X_train, y_train)  # Make predictions on the test set y_pred = best_model.predict(X_test) \n",
    "- Evaluate the model accuracy = accuracy_score(y_test, y_pred) print(f'Accuracy: {accuracy:.2f}')  \n",
    "- Print classification report for more detailed evaluation print(classification_report(y_test, y_pred)) \n",
    "- Use the trained model to make predictions on new data new_data = pd.DataFrame({     'Feature1': [value1],     'Feature2': [value2],   \n",
    "- Add more features as needed })  \n",
    "- Preprocess new data similarly to training data (handle missing values, encoding, scaling) new_data.fillna(0, inplace=True) new_data[categorical_columns] = le.transform(new_data[categorical_columns]) new_data = scaler.transform(new_data)  predicted_grade = best_model.predict(new_data) print(f'Predicted Grade: {predicted_grade[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b6bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e42e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ff083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
